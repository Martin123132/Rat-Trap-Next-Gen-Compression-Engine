# ğŸª¤ Rat-Trap â€” Next-Gen Compression Engine  

**"Time is money. Space is motion. Rat-Trap is both."**

Rat-Trap is a **high-performance, GMW-powered data compression system** built by Glyn Evans and Martin ollett, inspired by the **Motion-TimeSpace (MTS) physics framework**. Itâ€™s engineered to **trap chaotic data**â€”text, images, audio, structured recordsâ€”and reorganize it into the smallest, fastest, most efficient form possible.

Where conventional compression tools trade speed for size, **Rat-Trap defines the new speed-to-ratio standard.** By leveraging MTS principles of motion, resistance, and curvature memory, it captures entropy more efficiently and delivers **up to $93\times$ speedups** while maintaining competitive or superior compression ratios.

## ğŸš€ Why Rat-Trap? (The New Standard)

Rat-Trap's GMW format is not just a faster compressor; it's the **undisputed speed leader** for the largest, most critical AI and data science workloads. It renders the long-time standard `tar.gz` obsolete.

| Metric | GMW (ZSTD-3) | Tar/Gzip (Legacy Standard) | Tar/XZ (Slowest/Best Ratio) | Pure ZSTD (Modern Baseline) |
| :--- | :--- | :--- | :--- | :--- |
| **Image Compression Time** | **$\mathbf{2.54s}$** | $11.46s$ | $122.95s$ | $3.31s$ |
| **Speedup (vs. Gzip)** | **$4.5\times$ faster** | $1.0\times$ | $0.09\times$ | $3.5\times$ faster |
| **Audio Compression Time** | **$\mathbf{8.82s}$** | $36.04s$ | $236.70s$ | $1253.34s$ |
| **Speedup (vs. Tar/XZ)** | **$26.8\times$ faster** | $6.6\times$ faster | $1.0\times$ | $0.19\times$ faster |

  * **ğŸ¥‡ The Speed Leader:** GMW-ZSTD-1 is the **fastest archiver tested** for folder-level Image data, beating even bare ZSTD and LZ4.
  * **â± Up to $\mathbf{93\times}$ faster** than traditional methods like `tar.xz` (on Image data).
  * **âš–ï¸ The New Default:** GMW-ZSTD is consistently **$4\times$ to $8\times$ faster than `tar.gz`** while achieving better or comparable size.
  * **ğŸ§  Physics-Inspired Design** based on Motion-TimeSpace curvature dynamics.
  * **ğŸŒ Fully self-contained Python script**â€”no external build system required.

-----

## ğŸ§  How It Works

Rat-Trapâ€™s core compression engine is built around **GMW (Geometric Motion Wrapper)**â€”a custom archival format derived from MBT2 physics simulations. It optimizes for file aggregation and parallel processing, solving the I/O bottlenecks that choke traditional compression tools.

Key Innovations:

  * **Motion-TimeSpace Compression** â€“ Organizes data based on motion-derived entropy gradients, mimicking how tension diffuses in physical systems.
  * **Parallelized Bucket Packing** â€“ Optimized thread-based bucket construction for multi-core compression, which is the source of its massive speed advantage over single-stream `tar` pipes.
  * **Z-Order Encoding** â€“ Efficient voxel key mapping using Morton encoding for enhanced spatial data compaction.
  * **Adaptive ZSTD Layers** â€“ Configurable trade-offs between speed and compression depth (levels 1â€“9) to match specific latency requirements.
  * **Optional AES-GCM Encryption** â€“ Secure archives without losing performance.

-----

## ğŸ›  Installation

Rat-Trap is now published as a standard Python package. Install it into your
environment (and pull in the optional extras if you want the original
cryptography/xxhash helpers):

```bash
pip install .
# or build a wheel: python -m build

# optional extras
pip install .[crypto]
```

> **Note:** The default compression engine uses [Zstandard]. The package declares
> it as a dependency, but if you install manually without dependencies the CLI
> will automatically fall back to zlib and warn you.

-----

## âš™ï¸ Usage

Run Rat-Trap directly:

```bash
rat-trap --help
 ```

 The CLI exposes sub-commands instead of interactive prompts:

1.  `rat-trap compress <folder> <archive>` â€“ ingest a folder into a `.gmw` archive.
2.  `rat-trap extract <archive> <destination>` â€“ extract an archive back to disk.
3.  `rat-trap info <archive>` â€“ show stored metadata without extracting.
4.  `rat-trap serve <archive>` â€“ expose the archive via HTTP chunk streaming.

[Zstandard]: https://facebook.github.io/zstd/

### ğŸ“¦ Compress a folder

```bash
python gmw_tool.py
# ... prompts you for action ...
# Choose an action (1/2): 1
Enter the path of the folder to compress: ./dataset
Enter the output .gmw file name: data_archive.gmw
```

### ğŸ“‚ Extract a `.gmw` archive

```bash
python gmw_tool.py
# ... prompts you for action ...
# Choose an action (1/2): 2
Enter the path of the .gmw file to extract: data_archive.gmw
Enter the output folder: ./restored
```

## ğŸ” New Experimental Toolchain

To explore new data-transfer frontiers we now ship three experimental
spin-offs of the original `gmw_tool.py`. Each script keeps the familiar
CLI structure (`compress`, `extract`, `info`) so they can be benchmarked
side-by-side.

| Tool | Focus | Why it Matters |
| :--- | :--- | :--- |
| ` | Streaming pipelines | Pipes the tar writer straight into the compressor so multi-terabyte datasets can be archived with constant memory usage. Metadata retains timing and integrity stats for benchmarking. |
| `| Global deduplication | Splits files into hashed blocks, stores each block once, and replays them via a manifest. Great for corpora with repeated checkpoints or dataset shards. |
|  | SQLite content lake | Persists chunks in a queryable SQLite database and exposes an HTTP API for chunk streamingâ€”ideal for orchestrating LLM training clusters. |

All three scripts live at the repository root and can be executed
directly, e.g. `python gmw_tool_v3.py compress dataset dedup.gmw`.

-----


## ğŸ“Š Performance Highlights

The following benchmarks demonstrate Rat-Trap's ability to maximize speed while maintaining excellent compression. The GMW structure outperforms all tested alternatives for high-volume Image and Audio data.

| Data Type | Best GMW Time | Fastest Competitor | Speed Difference | Best GMW Ratio | Best Overall Ratio |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **Image** | **$\mathbf{1.31s}$ (ZSTD-1)** | Pure ZSTD ($3.31s$) | **$2.5\times$ faster** | $1.08$ (ZSTD-9) | $1.33$ (`tar.xz`) |
| **Audio** | **$\mathbf{8.82s}$ (ZSTD-3)** | `tar.gz` ($36.04s$) | **$4.1\times$ faster** | $1.41$ (ZSTD-9) | $1.65$ (`Brotli`) |
| **Text** | $0.047s$ (ZSTD-1) | **LZ4 ($\mathbf{0.0066s}$)** | Slower, but **$4\times$ smaller** file size. | $2.80$ (ZSTD-9) | $3.39$ (`tar.bz2`) |
| **Structured** | $0.035s$ (ZSTD-3) | **LZ4 ($\mathbf{0.0103s}$)** | Slower, but **$1.6\times$ smaller** file size. | $10.04$ (ZSTD-9) | $16.86$ (`tar.bz2`) |

  * **The Crux:** For Image and Audio, Rat-Trap is the fastest archiver by leveraging parallel I/O and GMW structure. For Text and Structured data, it offers a superior trade-off: marginally slower than raw LZ4, but delivering a vastly better (smaller) file size.

-----

## ğŸ”¬ Real-World Impact

Rat-Trap is an **economic advantage.**

A $\mathbf{4\times \text{ to } 93\times}$ compression speedup on petabyte-scale data pipelines translates directly to **tens of millions in compute savings** for cloud-scale platforms like OpenAI, Google DeepMind, and Meta. By dramatically reducing I/O wait times, Rat-Trap enables **faster AI model iteration, quicker checkpointing, and lower operational costs.**

-----

## ğŸ§¬ About Motion-TimeSpace (MTS)

Rat-Trap is built on the **Motion-TimeSpace physics framework**, which treats **motion, resistance, and curvature** as the foundation of physical processesâ€”including information. By applying these principles to data compression, Rat-Trap **mimics entropy diffusion** and achieves efficiency limits traditional, purely mathematical algorithms miss.

-----

## ğŸ§‘â€ğŸ”¬ Credits

  * **Rat-Trap** â€” Core compression tool designed and built by **Glyn Evans**
  * **Physics Engine** â€” Based on **Motion-TimeSpace Theory (MTS)** by **Martin Ollett**

-----

## ğŸª¤ License

Rat-Trap is free for personal and academic use. For commercial use or integration into proprietary platforms, please [contact us] ollett123123@outlook.com.


â¸»

1. High-Level Architecture Overview

                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚    GMW: GEOMETRIC MOTION WRAPPER     â”‚
                   â”‚        (SQLite Archive Engine)       â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Folder  â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ Chunking  â”‚â”€â”€â”€â”€â”€â–¶â”‚ Compression â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ SQLite Store â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚                   â”‚                    â”‚
                             â”‚                   â”‚                    â–¼
                             â”‚                   â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â–¼                   â”‚         â”‚   Metadata Tables   â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚         â”‚ (files, chunks, meta)â”‚
                     â”‚  Z-Order (Î¦Î“)  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â¸»

2. Data Flow: Folder â†’ Chunking â†’ Compression â†’ SQLite

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                               INGEST PIPELINE                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[FOLDER]
   |
   â”œâ”€ Read file paths
   â–¼
[CHUNK BUILDER]
   - Read 512KB / 1MB blocks
   - Compute BLAKE2b(16) digest
   - Dedup check (exist? skip storage)
   |
   â–¼
[MTS GEOMETRIC ORDERING]
   Apply Z-Order Curve (Morton Index)
   Reorder chunks for maximal locality
   |
   â–¼
[COMPRESSOR]
   - zstd (default)
   - zlib fallback
   |
   â–¼
[SQLITE ARCHIVE]
   - chunks table
   - files table
   - metadata table


â¸»

3. Z-Order (Morton) Encoding Pipeline Diagram

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   File Metadata      â”‚
â”‚ (path, mtime, size)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           |
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Key Generator â”‚
    â”‚  Î¦ = motion   â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           |
           â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Morton Encoder â”‚  <--- Interleave bits into Z-curve
   â”‚ (Z-Order map)  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           |
           â–¼
  [GEOMETRIC SORTED ORDER]


â¸»

4. Chunk Map Visualization (SQLite)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SQLite: chunks table â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ id (TEXT)         compressor   raw_size   data(BLOB)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 9fa21...          "zstd"       524288     <compressed blob>                       â”‚
â”‚ 01bb3...          "zstd"       524288     <compressed blob>                       â”‚
â”‚ a91f0...          "zstd"       183920     <compressed blob>                       â”‚
â”‚ ...                                                                            ...â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Representation:

[Chunk ID] â†’ [Block of compressed bytes]
      â”‚
      â””â”€â”€ referenced by files.chunk_ids[]


â¸»

5. File Entry Reconstruction Diagram

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 files table                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ path: "images/cat001.png"                   â”‚
â”‚ size: 1,048,576                             â”‚
â”‚ chunk_ids: ["9fa21...", "01bb3..."]         â”‚
â”‚ chunk_sizes: [524288, 524288]               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

     RECONSTRUCTION:

   chunk_ids[0] â†’ decompress â†’ write first 524288 bytes
   chunk_ids[1] â†’ decompress â†’ write next 524288 bytes


â¸»

6. Parallel Bucket Compression Layout

      BEFORE ORDERING                          AFTER Z-ORDERING
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”
â”‚ A001 â”‚ Z019  â”‚ G3004  â”‚ B002 â”‚ C1F â”‚ --> â”‚ A001 â”‚ A002 â”‚ A003 â”‚ A004 â”‚ A005 â”‚
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚      â”‚      â”‚      â”‚
                                                 â–¼      â–¼      â–¼      â–¼
                                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Parallel Buckets â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                       â”‚   B1   â”‚   B2   â”‚   B3   â”‚      B4         â”‚
                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Each bucket compressed independently â†’ TRUE parallel compression.

â¸»

7. Extract Pipeline Diagram

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              EXTRACTION PIPELINE             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[SQLite Archive]
   |
   â”œâ”€ SELECT * FROM files ORDER BY ordering
   |
   â–¼
[File Entry]
   |
   â”œâ”€ for each chunk_id:
   |      SELECT data FROM chunks
   |      decompress()
   |      write bytes
   |
   â–¼
[Reconstructed File]


â¸»

8. HTTP Chunk Server Routing Diagram

                GMW HTTP SERVER
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ GET /manifest                   â”‚
    â”‚   â†’ returns metadata + file map â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ GET /chunks/<chunk_id>          â”‚
    â”‚   â†’ returns compressed blob      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CLIENT FLOW:

    /manifest
       â–¼
   get chunk_ids[]
       â–¼
  fetch /chunks/<id>
       â–¼
 decompress + assemble


â¸»

9. GMW vs tar.gz Pipeline Comparison

                    TRADITIONAL PIPELINE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Folder   â”‚ ---> â”‚   tarball    â”‚ ---> â”‚ gzip / xz     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      1 core used        SEQUENTIAL            SEQUENTIAL

                   GMW GEOMETRIC PIPELINE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Folder   â”‚ --> â”‚ Chunking    â”‚ Z-Ordering  â”‚ Parallel     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                       â”‚
                                       â–¼
                                 [SQLite Lake]
             MULTI-CORE PARALLELISM, NO TARBALL, FAST I/O


â¸»

